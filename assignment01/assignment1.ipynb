{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors\n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.import TODO as TODO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_iris_dataset():\n",
    "    from sklearn import datasets\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_iris_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing\n",
    "\n",
    "1) Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains data of morphologic variations in Iris flowers. It has 4 input features (sepal length, sepal width, petal length, and petal width) and 3 classification targets which denote the corresponding type of Iris flowers: Iris setosa, Iris virginica, and Iris versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 150\n",
      "Number of features: 4\n",
      "Samples per class:\n",
      "      0  :  50\n",
      "      1  :  50\n",
      "      2  :  50\n",
      "Mean and standard deviation of each feature: \n",
      "     Sepal-length: 5.8433 , 0.8253\n",
      "     Sepal-width: 3.0573 , 0.4344\n",
      "     Petal-length: 3.7580 , 1.7594\n",
      "     Petal-width: 1.1993 , 0.7597\n"
     ]
    }
   ],
   "source": [
    "# Print the number of samples in the dataset\n",
    "n_samples, n_features = X.shape\n",
    "print(\"Number of samples:\", n_samples)\n",
    "print(\"Number of features:\", n_features)\n",
    "\n",
    "# Class distribution\n",
    "print(\"Samples per class:\")\n",
    "index, samples_count = np.unique(y, return_counts=True)\n",
    "samples_per_class = dict(zip(index, samples_count))\n",
    "for index in samples_per_class:\n",
    "    print('{:>5}'.format(''), index, ' : ', samples_per_class[index])\n",
    "\n",
    "# Finding the mean and standard deviation of each feature\n",
    "f_mean = (np.mean(X, axis=0))\n",
    "f_std = (np.std(X, axis=0))\n",
    "print(\"Mean and standard deviation of each feature: \")\n",
    "print(\"{:>5}Sepal-length:\".format(''), \"%.4f\" % f_mean[0], \", %.4f\" % f_std[0])\n",
    "print(\"{:>5}Sepal-width:\".format(''), \"%.4f\" % f_mean[1], \", %.4f\" % f_std[1])\n",
    "print(\"{:>5}Petal-length:\".format(''), \"%.4f\" % f_mean[2], \", %.4f\" % f_std[2])\n",
    "print(\"{:>5}Petal-width:\".format(''), \"%.4f\" % f_mean[3], \", %.4f\" %f_std[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualize the variables Sepal length and Petal length in a scatter plot (Sepal length on the x-axis, petal length on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Sepal-length (x) and Petal-length (y) data to a scatter plot\n",
    "plt.scatter(X[:,0], X[:,2], c=y, cmap=plt.cm.spring) # Colour according to class\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X_train]\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]]\n",
      "[X_test]\n",
      "[[5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "    # samling evenly with regard to TRAIN_SET_RATIO\n",
    "    # 70% for training and 30% for test\n",
    "    TRAIN_SET_RATIO = 0.7\n",
    "    TEST_SET_RATIO = 1 - TRAIN_SET_RATIO\n",
    "\n",
    "    # if the input data is random, just take the continuous portion\n",
    "    # otherwise, in a ordered data sampling is required to guarantee training set have all the data\n",
    "    is_random = False\n",
    "\n",
    "    if is_random:\n",
    "        nx_split = int(TRAIN_SET_RATIO * X.shape[0])\n",
    "        ny_split = int(TRAIN_SET_RATIO * y.shape[0])\n",
    "        X_train = X[:nx_split]\n",
    "        X_test = X[nx_split:]\n",
    "        y_train = y[:ny_split]\n",
    "        y_test = y[ny_split:]\n",
    "    else:\n",
    "        index_class, class_counts = np.unique(y, return_counts=True)\n",
    "        samples_class = dict(zip(index_class, samples_count))\n",
    "        samples = int(samples_class[0]*TRAIN_SET_RATIO)\n",
    "        X_train = X[: samples]\n",
    "        X_test = X[samples : samples_class[0]]\n",
    "        y_train = y[: samples]\n",
    "        y_test = y[samples : samples_class[0]]\n",
    "        pos = int(0)\n",
    "        for index in samples_class:\n",
    "            samples = int(samples_class[index]*TRAIN_SET_RATIO)\n",
    "            num = int(samples_class[index])\n",
    "            if index != 0:\n",
    "                X_train = np.concatenate((X_train, X[pos : pos + samples]), axis=0)\n",
    "                X_test = np.concatenate((X_test, X[pos + samples : pos + num]), axis=0)\n",
    "                y_train = np.concatenate((y_train, y[pos : samples + pos]), axis=0)\n",
    "                y_test = np.concatenate((y_test, y[pos +samples : pos + num]), axis=0)\n",
    "            pos = pos + num\n",
    "\n",
    "    # Slicing the 2D arrays\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def show_data(X_train, X_test):\n",
    "    print(\"[X_train]\")\n",
    "    print(X_train)\n",
    "    print(\"[X_test]\")\n",
    "    print(X_test)\n",
    "    pass\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "show_data(X_train, X_test)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max rescaling of training data values\n",
    "vmin = X_train.min(axis=0) # Find min values of each feature\n",
    "vmax = X_train.max(axis=0) # Find max values of each feature\n",
    "\n",
    "for i in range(4):\n",
    "    X_train[:,i] = (X_train[:,i] - vmin[i]) / (vmax[i] - vmin[i])\n",
    "\n",
    "# Now rescale test data\n",
    "for i in range(4):\n",
    "    X_test[:,i] = (X_test[:,i] - vmin[i]) / (vmax[i] - vmin[i])\n",
    "# print(X_train)\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighborsClassifier`. \n",
    "\n",
    "Use Euclidean distance to determine the nearest neighbors.\n",
    "You can ignore the optional parameter `distance_metric`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For everyone else:**  \n",
    "Implement the kNN algorithm with distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighborsClassifier`.\n",
    "\n",
    "The parameter `distance_metric` will either contain the string `uniform` or a function. If the value is `uniform`, the classifier should use the Euclidean distance for determining nearest neighbors and uniform weighting. If the value is a function, the classifier should use the function as distance metric and perform distance-weighted classification. An example distance metric is provided with `euclidean_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    # distance_metric : {‘uniform’, function}, optional \n",
    "    # This is optional and the default is 'uniform'\n",
    "    def __init__(self, k, distance_metric='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,k).\n",
    "        \"\"\"\n",
    "        n, k = X.shape\n",
    "        Y = X\n",
    "        ans = np.array([0 for col in range(n)])\n",
    "        for i in range(n):\n",
    "            find_neighbor = [(0.0,0) for col in range(self.X.shape[0])]\n",
    "            for j in range(self.X.shape[0]):\n",
    "                dist = 0.0\n",
    "                if type(self.distance_metric)==type('uniform') and self.distance_metric == 'uniform':\n",
    "                    dist = euclidean_distance(Y[i], self.X[j])\n",
    "                else:\n",
    "                    dist = self.distance_metric(Y[i], self.X[j])\n",
    "                find_neighbor[j] = (dist, self.y[j])\n",
    "            find_neighbor.sort()\n",
    "            catagory = {}\n",
    "            for j in range(self.k):\n",
    "                if find_neighbor[j][1] in catagory:\n",
    "                    catagory[find_neighbor[j][1]] += 1\n",
    "                else:\n",
    "                    catagory[find_neighbor[j][1]] = 1\n",
    "            max_key = 0\n",
    "            max_value = 0\n",
    "            for j, l in catagory.items():\n",
    "                if l > max_value:\n",
    "                    max_key = j\n",
    "                    max_value = l\n",
    "            ans[i] = max_key\n",
    "        return ans\n",
    "\n",
    "def uniform_distance(x1, x2):\n",
    "    return np.amax(np.absolute(x1 - x2))\n",
    "    \n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.absolute(x1 - x2))\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))\n",
    "\n",
    "# testing for class\n",
    "myKNN = KNearestNeighbors(1)\n",
    "myKNN.fit(X_train, y_train)\n",
    "y_pred_train = myKNN.predict(X_train)\n",
    "y_pred_test = myKNN.predict(X_test)\n",
    "#assert np.array_equal(y_pred_train, y_train)\n",
    "#assert ~np.array_equal(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation\n",
    "\n",
    "1) Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "[0.33333333 0.         0.33333333]\n",
      "[0.33333333 0.         0.5       ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    assert len(y_pred) == len(y_true), \"Predict and True size not match\"                        \n",
    "\n",
    "    # y_true suppose containing all classification types\n",
    "    # returning an 1d array with precision for each types\n",
    "\n",
    "    # sample_per_classe is a dict for indicated number of count for each types\n",
    "    types, type_counts = np.unique(y_true, return_counts=True)\n",
    "\n",
    "    y_precision = np.zeros(len(types), dtype=float)\n",
    "    \n",
    "    for type_index in range(len(types)):\n",
    "        temp = np.zeros(len(types), dtype=float)\n",
    "        for y_index in range(len(y_true)):\n",
    "            if y_pred[y_index] == types[type_index]:\n",
    "                temp[y_true[y_index]] += 1\n",
    "        y_precision[type_index] = temp[type_index] / np.sum(temp)\n",
    "    # print(\"Precision: \", y_precision)\n",
    "    return y_precision\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    assert len(y_pred) == len(y_true), \"Predict and True size not match\"                        \n",
    "    types, type_counts = np.unique(y_true, return_counts=True)\n",
    "    temp = np.zeros(len(types), dtype=float)\n",
    "    y_recall = np.zeros(len(types), dtype=float)\n",
    "    \n",
    "    for type_index in range(len(types)):\n",
    "        temp = np.zeros(len(types), dtype=float)\n",
    "        for y_index in range(len(y_true)):\n",
    "            if y_true[y_index] == types[type_index]:\n",
    "                temp[y_pred[y_index]] += 1\n",
    "        y_recall[type_index] = temp[type_index] / np.sum(temp)\n",
    "    # print(\"Recall: \",y_recall)\n",
    "    return y_recall\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    y_precision = precision(y_pred, y_true)  \n",
    "    y_recall = recall(y_pred, y_true)\n",
    "    assert (len(y_precision) == len(y_recall)), \"Precision and Recall size not match\"\n",
    "    y_f1score = np.zeros(len(y_recall), dtype=float)  \n",
    "    for index in range(len(y_f1score)):\n",
    "        y_f1score[index] = 2 * y_precision[index] * y_recall[index] / (y_precision[index] + y_recall[index])\n",
    "    # print(\"f1 score: \",y_f1score)\n",
    "    return y_f1score                        \n",
    "\n",
    "\n",
    "def self_test():\n",
    "    y_t = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "    y_p = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "    print(recall(y_p, y_t))\n",
    "    print(precision(y_p, y_t))\n",
    "    \n",
    "    y_p = [0, 1, 1, 2, 0, 0, 1, 1, 2]\n",
    "    print(recall(y_p, y_t))\n",
    "    print(precision(y_p, y_t))\n",
    "    \n",
    "    y_t = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    y_p = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
    "    print(recall(y_p, y_t))\n",
    "    print(precision(y_p, y_t))\n",
    "    pass\n",
    "\n",
    "def test_recall(y_pred, y_true):\n",
    "    y = list(range(10))\n",
    "    y_shift1 = list(range(1, 11))\n",
    "    print(y, y_shift1)\n",
    "    y_recall = recall(y, y_shift1)\n",
    "    all_zeros = np.ones(len(y_recall), dtype=float);\n",
    "    assert np.array_equal(all_zeros, y_recall), \"recall() implement error, Recall should all be 0\"\n",
    "    \n",
    "\n",
    "    \n",
    "    y_recall = recall(y_true, y_true)\n",
    "    y_precision= precision(y_true, y_true)\n",
    "    y_f1score = f1score(y_true, y_true)\n",
    "    all_ones = np.ones(len(y_recall), dtype=float);\n",
    "    assert np.array_equal(all_ones, y_recall), \"recall() implement error, Recall should all be 1\"\n",
    "    assert np.array_equal(all_ones, y_precision), \"precision() implement error, Recall should all be 1\"\n",
    "    assert np.array_equal(all_ones, y_f1score), \"f1score() implement error, Recall should all be 1\"\n",
    "    pass\n",
    "                             \n",
    "test_recall(y_pred_train, y_train)\n",
    "self_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Evaluate the performance of kNN with uniform weighting on the Iris dataset for `k=1,3,5`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Print all scores per model. What do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "Evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "      Precision\n",
      "           1 -NN classifier:  [1. 1. 1.]\n",
      "           3 -NN classifier:  [1.         0.92105263 1.        ]\n",
      "           5 -NN classifier:  [1.        0.8974359 1.       ]\n",
      "      Recall\n",
      "           1 -NN classifier:  [1. 1. 1.]\n",
      "           3 -NN classifier:  [1.         1.         0.91428571]\n",
      "           5 -NN classifier:  [1.         1.         0.88571429]\n",
      "      F1 score\n",
      "           1 -NN classifier:  [1. 1. 1.]\n",
      "           3 -NN classifier:  [1.         0.95890411 0.95522388]\n",
      "           5 -NN classifier:  [1.         0.94594595 0.93939394]\n",
      "Test Data\n",
      "      Precision\n",
      "           1 -NN classifier:  [1. 1. 1.]\n",
      "           3 -NN classifier:  [1. 1. 1.]\n",
      "           5 -NN classifier:  [1. 1. 1.]\n",
      "      Recall\n",
      "           1 -NN classifier:  [1. 1. 1.]\n",
      "           3 -NN classifier:  [1. 1. 1.]\n",
      "           5 -NN classifier:  [1. 1. 1.]\n",
      "      F1 score\n",
      "           1 -NN classifier:  [1. 1. 1.]\n",
      "           3 -NN classifier:  [1. 1. 1.]\n",
      "           5 -NN classifier:  [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "kNN_list = list()\n",
    "k_list = list()\n",
    "y_pred_train_list = list()\n",
    "y_pred_test_list = list()\n",
    "data_str_list = [\"Train Data\", \"Test Data\"]\n",
    "func_str_list = [\"Precision\", \"Recall\" ,\"F1 score\"]\n",
    "func_list = [precision, recall , f1score]\n",
    "y_pred_list = [y_pred_train_list, y_pred_test_list]\n",
    "y_true_list = [y_train, y_test]\n",
    "# creating 3 clssifiers with k=1, 3, 5 \n",
    "\n",
    "for i in range(3):\n",
    "    k_list.append(2 * i + 1)\n",
    "\n",
    "for i in range(len(k_list)):\n",
    "    k = k_list[i]\n",
    "    kNN_list.append(KNearestNeighbors(k, uniform_distance))\n",
    "    kNN_list[i].fit(X_train, y_train)\n",
    "    y_pred_train_list.append(kNN_list[i].predict(X_train))\n",
    "    y_pred_test_list.append(kNN_list[i].predict(X_test))\n",
    "    # print(k)\n",
    "    # print(y_pred_train_list[i])\n",
    "    # print(y_pred_test_list[i])\n",
    "\n",
    "    \n",
    "for d_index in range(len(data_str_list)):\n",
    "    print(data_str_list[d_index])\n",
    "    for f_index in range(len(func_list)):\n",
    "        print(\"{:>5}\".format(''), func_str_list[f_index])\n",
    "        for i in range(len(k_list)):\n",
    "            print(\"{:>10}\".format(''), i * 2 + 1,\"-NN classifier: \", func_list[f_index](y_pred_list[d_index][i], y_true_list[d_index]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your observations here and report your results.* (double klick here to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain why kNN with `k=1` achieves perfect results on the training data. Why is it not the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with k=1 results will result in overfitting for testing data. This overfitting effect will become obvious when dealing with classes that have overlapping area. In the Iris classfication data, the Iris type-1 and type-2 are overlapping with each other. So testing data located in these area would only be classified by only 1 nearest neighbor.\n",
    "\n",
    "Reference: https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}