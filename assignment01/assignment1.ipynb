{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors\n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_iris_dataset():\n",
    "    from sklearn import datasets\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_iris_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing\n",
    "\n",
    "1) Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains data of morphologic variations in Iris flowers. It has 4 input features (sepal length, sepal width, petal length, and petal width) and 3 classification targets which denote the corresponding type of Iris flowers: Iris setosa, Iris virginica, and Iris versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of samples in the dataset\n",
    "n_samples, n_features = X.shape\n",
    "print(\"Number of samples:\", n_samples)\n",
    "print(\"Number of features:\", n_features)\n",
    "\n",
    "# Class distribution\n",
    "print(\"Samples per class:\")\n",
    "index, samples_count = np.unique(y, return_counts=True)\n",
    "samples_per_class = dict(zip(index, samples_count))\n",
    "for index in samples_per_class:\n",
    "    print('{:>5}'.format(''), index, ' : ', samples_per_class[index])\n",
    "\n",
    "# Finding the mean and standard deviation of each feature\n",
    "f_mean = (np.mean(X, axis=0))\n",
    "f_std = (np.std(X, axis=0))\n",
    "print(\"Mean and standard deviation of each feature: \")\n",
    "print(\"{:>5}Sepal-length:\".format(''), \"%.4f\" % f_mean[0], \", %.4f\" % f_std[0])\n",
    "print(\"{:>5}Sepal-width:\".format(''), \"%.4f\" % f_mean[1], \", %.4f\" % f_std[1])\n",
    "print(\"{:>5}Petal-length:\".format(''), \"%.4f\" % f_mean[2], \", %.4f\" % f_std[2])\n",
    "print(\"{:>5}Petal-width:\".format(''), \"%.4f\" % f_mean[3], \", %.4f\" %f_std[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualize the variables Sepal length and Petal length in a scatter plot (Sepal length on the x-axis, petal length on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sepal-length (x) and Petal-length (y) data to a scatter plot\n",
    "plt.scatter(X[:,0], X[:,2], c=y, cmap=plt.cm.spring) # Colour according to class\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "    # 70% for training and 30% for test\n",
    "    nx_split = int(0.7 * X.shape[0])\n",
    "    ny_split = int(0.3 * y.shape[0])\n",
    "\n",
    "    # Slicing the 2D arrays\n",
    "    X_train = X[:nx_split]\n",
    "    X_test = X[nx_split:]\n",
    "    y_train = y[:ny_split]\n",
    "    y_test = y[ny_split:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max rescaling of training data values\n",
    "vmin = X_train.min(axis=0) # Find min values of each feature\n",
    "vmax = X_train.max(axis=0) # Find max values of each feature\n",
    "\n",
    "for i in range(4):\n",
    "    X_train[:,i] = (X_train[:,i] - vmin[i]) / (vmax[i] - vmin[i])\n",
    "\n",
    "# Now rescale test data\n",
    "for i in range(4):\n",
    "    X_test[:,i] = (X_test[:,i] - vmin[i]) / (vmax[i] - vmin[i])\n",
    "# print(X_train)\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighborsClassifier`. \n",
    "\n",
    "Use Euclidean distance to determine the nearest neighbors.\n",
    "You can ignore the optional parameter `distance_metric`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For everyone else:**  \n",
    "Implement the kNN algorithm with distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighborsClassifier`.\n",
    "\n",
    "The parameter `distance_metric` will either contain the string `uniform` or a function. If the value is `uniform`, the classifier should use the Euclidean distance for determining nearest neighbors and uniform weighting. If the value is a function, the classifier should use the function as distance metric and perform distance-weighted classification. An example distance metric is provided with `euclidean_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    def __init__(self, k, distance_metric='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,k).\n",
    "        \"\"\"\n",
    "        # Implement your solution here. Michelle is working on it. :D\n",
    "        pass\n",
    "\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation\n",
    "\n",
    "1) Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    pass\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    pass\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Evaluate the performance of kNN with uniform weighting on the Iris dataset for `k=1,3,5`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Print all scores per model. What do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "Evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your observations here and report your results.* (double klick here to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain why kNN with `k=1` achieves perfect results on the training data. Why is it not the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your response here.* (double klick here to edit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}