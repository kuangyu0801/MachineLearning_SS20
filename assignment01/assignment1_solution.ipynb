{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors\n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_iris_dataset():\n",
    "    from sklearn import datasets\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_iris_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing\n",
    "\n",
    "1) Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The dataset consists of `150` samples of flowers. Each flower is described by the features `sepal length`, `sepal width`, `petal length`, and `petal width` and belongs to one of three species `Iris setosa`, `Iris virginica`, and `Iris versicolor`. The species is the classification target. All features are numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['setosa', 'versicolor', 'virginica']\n",
    "feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "print(f'#samples: {X.shape[0]}')\n",
    "\n",
    "for class_name, class_count in zip(class_names, np.bincount(y)):\n",
    "    print(f'- class {class_name}: {class_count}')\n",
    "print()\n",
    "    \n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "for feature_idx, feature_name in enumerate(feature_names):\n",
    "    print(f'{feature_name}:')\n",
    "    print(f'- mean: {mean[feature_idx]:.2f}')\n",
    "    print(f'- std: {std[feature_idx]:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualize the variables Sepal length and Petal length in a scatter plot (Sepal length on the x-axis, petal length on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    ax.scatter(X[y == class_idx, 0], X[y == class_idx, 2], label=class_name)\n",
    "ax.set_xlabel('sepal length [cm]')\n",
    "ax.set_ylabel('petal length [cm]')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "    np.random.seed(2020)  # Ensure that the random split always returns the same result.\n",
    "    \n",
    "    threshold = int(0.7*X.shape[0])\n",
    "    rnd_idx = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    X_train = X[rnd_idx[:threshold]]\n",
    "    X_test = X[rnd_idx[threshold:]]\n",
    "    y_train = y[rnd_idx[:threshold]]\n",
    "    y_test = y[rnd_idx[threshold:]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_min = np.min(X_train, axis=0)\n",
    "X_max = np.max(X_train, axis=0)\n",
    "\n",
    "def min_max_scale(X):\n",
    "    return (X - X_min) / (X_max - X_min)\n",
    "\n",
    "X_train = min_max_scale(X_train)\n",
    "X_test = min_max_scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighborsClassifier`. \n",
    "\n",
    "Use Euclidean distance to determine the nearest neighbors.\n",
    "You can ignore the optional parameter `distance_metric`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For everyone else:**  \n",
    "Implement the kNN algorithm with distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighborsClassifier`.\n",
    "\n",
    "The parameter `distance_metric` will either contain the string `uniform` or a function. If the value is `uniform`, the classifier should use the Euclidean distance for determining nearest neighbors and uniform weighting. If the value is a function, the classifier should use the function as distance metric and perform distance-weighted classification. An example distance metric is provided with `euclidean_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    def __init__(self, k, distance_metric='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,d), \n",
    "        where n is the number of samples and d is the number of features.\n",
    "        \"\"\"\n",
    "        if self.distance_metric == 'uniform':\n",
    "            dist = euclidean_distance\n",
    "        else:\n",
    "            dist = self.distance_metric\n",
    "            \n",
    "        # Compute pairwise distances between inputs and training samples.\n",
    "        pw_distances = np.array([[dist(x1, x2) for x1 in X] for x2 in self.X])\n",
    "        # Identify k nearest neighbors for each input sample.\n",
    "        neighbors = np.argsort(pw_distances, axis=0)[:self.k].T\n",
    "        \n",
    "        labels = []\n",
    "        for idx, nb in enumerate(neighbors):\n",
    "            candidate_labels = np.unique(y_train[nb])\n",
    "            candidate_weights = []\n",
    "\n",
    "            for candidate in candidate_labels:\n",
    "                if self.distance_metric == 'uniform': # uniform weights\n",
    "                    candidate_weight = np.sum(self.y[nb] == candidate)\n",
    "                else: # distance-weighted\n",
    "                    weights = 1.0/pw_distances[nb, idx][self.y[nb] == candidate]\n",
    "                    # If distance is 0, the corresponding weight will be infinity,\n",
    "                    # which results in us just looking up the correct label or performing 1-NN.\n",
    "                    candidate_weight = np.sum(weights)\n",
    "                \n",
    "                candidate_weights.append(candidate_weight)\n",
    "            \n",
    "            # Select the class label with highest weight.\n",
    "            label_idx = np.argmax(candidate_weights)\n",
    "            label = candidate_labels[label_idx]\n",
    "            labels.append(label)\n",
    "        \n",
    "        return np.array(labels)\n",
    "\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation\n",
    "\n",
    "1) Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    # We compute the macro-average\n",
    "    labels = set(y_pred).union(set(y_true))\n",
    "    precisions = list()\n",
    "    for label in labels:\n",
    "        tp, fp, _, _ = tp_fp_tn_fn(y_pred, y_true, label)\n",
    "        if (tp + fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        precisions.append(prec)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    # We compute the macro-average\n",
    "    labels = set(y_pred).union(set(y_true))\n",
    "    recalls = list()\n",
    "    for label in labels:\n",
    "        tp, _, _, fn = tp_fp_tn_fn(y_pred, y_true, label)\n",
    "        recalls.append(tp / (tp + fn))\n",
    "    return np.mean(recalls)\n",
    "\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # We compute the macro-average\n",
    "    labels = set(y_pred).union(set(y_true))\n",
    "    f1scores = list()\n",
    "    for label in labels:\n",
    "        tp, fp, _, fn = tp_fp_tn_fn(y_pred, y_true, label)\n",
    "        if (tp + fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        rec = tp / (tp + fn)\n",
    "        f1scores.append(2 * (prec * rec) / (prec + rec))\n",
    "    return np.mean(f1scores)\n",
    "\n",
    "\n",
    "def tp_fp_tn_fn(y_pred, y_true, positive_label):\n",
    "    # Count true positive, false positives, true negatives, false negatives for a specific class.\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for yp, yt in zip(y_pred, y_true):\n",
    "        if yp == yt and yt == positive_label: # tp\n",
    "            tp += 1\n",
    "        elif yp != yt and yt == positive_label: # fp\n",
    "            fp += 1\n",
    "        elif yp == yt and yt != positive_label: # tn\n",
    "            tn += 1\n",
    "        else: # fn\n",
    "            fn += 1\n",
    "    return tp, fp, tn, fn\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Evaluate the performance of kNN with uniform weighting on the Iris dataset for `k=1,3,5`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Print all scores per model. What do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "Evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (1, 3, 5)\n",
    "metrics = ('uniform', 'euclidean')\n",
    "hyperparameters = [(k, metric) for metric in metrics for k in ks]\n",
    "\n",
    "scores = []\n",
    "for k, metric in hyperparameters:\n",
    "        classifier = KNearestNeighbors(\n",
    "            k=k, \n",
    "            distance_metric='uniform' if metric == 'uniform' else euclidean_distance\n",
    "        )\n",
    "        classifier.fit(X_train, y_train)\n",
    "        yhat_train = classifier.predict(X_train)\n",
    "        yhat_test = classifier.predict(X_test)\n",
    "                \n",
    "        scores.append([\n",
    "            [fnc(yhat, y) for fnc in (precision, recall, f1score)] \n",
    "            for yhat, y in ((yhat_train, y_train), (yhat_test, y_test))\n",
    "        ])\n",
    "        \n",
    "scores = np.array(scores)\n",
    "ks = np.array(ks)\n",
    "fig, ax = plt.subplots(3, 2, figsize=(8, 8), sharex=True, sharey=True)\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        ax[row, col].bar(ks-0.25, scores[:3, col, row], width=0.5, label='Uniform')\n",
    "        ax[row, col].bar(ks+0.25, scores[3:, col, row], width=0.5, label='Euclidian')\n",
    "        ax[row, col].set_ylim((0.8, 1.0))\n",
    "        \n",
    "ax[0, 0].set_ylabel('Precision')\n",
    "ax[1, 0].set_ylabel('Recall')\n",
    "ax[2, 0].set_ylabel('F1-Score')\n",
    "ax[0, 0].set_title('Training')\n",
    "ax[0, 1].set_title('Test')\n",
    "ax[-1, 0].set_xlabel('k')\n",
    "ax[-1, 1].set_xlabel('k')\n",
    "ax[-1, 0].set_xticks(ks)\n",
    "ax[0, 1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- distance-weighted kNN achieves perfect results on training data due to infinity-valued weights for training samples\n",
    "- to identify the best classifier we have to look only at the test data\n",
    "- 1-NN performs worst of all options\n",
    "- the choice of weighting does not matter in this use case, but if the sample is known distance-weighting will provide correct results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain why kNN with `k=1` achieves perfect results on the training data. Why is it not the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a sample is already in the training data, 1-NN will look up this sample and return the corresponding class. Therefore it will always achieve perfect results on the training data. This behavior does not translate to unseen data, which is shown in the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
