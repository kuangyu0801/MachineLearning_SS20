{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Naive Bayes and Text Classification\n",
    "\n",
    "Only use the already imported library `numpy`. Make sure that the `spamham.txt` dataset is in the same directory as the notebook.\n",
    "\n",
    "List your team members (name and immatriculation number) in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Your names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_spamham_dataset():\n",
    "    import string\n",
    "    \n",
    "    with open('spamham.txt', mode='r', encoding='utf-8') as f:\n",
    "        rows = [l.strip().split('\\t')[:2] for l in f]\n",
    "    \n",
    "    y, X = zip(*rows)\n",
    "    X =[x.translate(str.maketrans('', '', string.punctuation)).lower().split() for x in X]\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "\n",
    "X, y = load_spamham_dataset()\n",
    "\n",
    "print('Sample:')\n",
    "print(f'{y[0]}: {X[0]}')\n",
    "print(f'{y[2]}: {X[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Spam Classification with Naive Bayes\n",
    "\n",
    "Check out the description of the dataset at [https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "\n",
    "Implement a Naive Bayes classifier with Laplace smoothing to detect whether a text message is spam or ham (not spam).\n",
    "\n",
    "A text message is represented by a list of string tokens as shown above.\n",
    "The classification target is binary and the two possible labels are the strings `'spam'` and `'ham'`.\n",
    "\n",
    "Fill out the methods in `NaiveBayesSpamClassifier` to train (`fit`) and predict (`predict`). Feel free to introduce new fields and methods based on your needs, but the methods `fit` and `predict` are required and their interface should not be changed.\n",
    "\n",
    "Hint: Try to map the text messages to word frequency vectors by counting how often each word occurs in a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import log\n",
    "\n",
    "# Implement your solution here.\n",
    "class NaiveBayesSpamClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.total_docs = None\n",
    "        self.classes = None\n",
    "        self.docs_per_class = None\n",
    "        self.vocabulary = None\n",
    "        self.vocabulary_size = None\n",
    "        self.collection_frequency = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X is a list of `n` text messages. Each text message is a list of strings with at least length one.\n",
    "        y is a list of `n` labels either the string 'spam' or the string 'ham'.\n",
    "        \"\"\"\n",
    "        self.total_docs = len(X)\n",
    "        self.classes = set(y)\n",
    "        self.docs_per_class = Counter(y)\n",
    "        self.vocabulary = set(term for document in X for term in document)\n",
    "        self.vocabulary_size = len(self.vocabulary)\n",
    "        self.collection_frequency = defaultdict(int)\n",
    "        self.total_terms_per_class = defaultdict(int)\n",
    "        for document, class_label in zip(X, y):\n",
    "            for term in document:\n",
    "                self.collection_frequency[(term, class_label)] += 1\n",
    "                self.total_terms_per_class[class_label] += 1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X is a list of `n` text messages. Each text message is a list of strings with at least length one.\n",
    "        The method returns a list of `n` strings, i.e. classification labels ('spam' or 'ham').\n",
    "        \"\"\"\n",
    "        yhat = []\n",
    "        for document in X:\n",
    "            term_frequency = Counter(document)\n",
    "            class_likelihood = dict()\n",
    "            for ci in self.classes:\n",
    "                # We compute the log-likelihood.\n",
    "                # According to logarithm laws, the products are mapped to sums and the exponent is mapped to a multiplication.\n",
    "                prior = log(self.docs_per_class[ci] / self.total_docs)\n",
    "                \n",
    "                class_likelihood[ci] = prior + \\\n",
    "                    sum(\n",
    "                        term_frequency[tj] * log(  \n",
    "                            (self.collection_frequency[(tj, ci)] + 1) /\n",
    "                            (self.total_terms_per_class[ci] + self.vocabulary_size)\n",
    "                    ) for tj in term_frequency)\n",
    "                \n",
    "            # Choose class label with highest log-likelihood.\n",
    "            yhat.append(max(class_likelihood.items(), key=lambda t: t[1])[0])\n",
    "        return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code will evaluate your classifier.\n",
    "class HamClassifier(object):\n",
    "    \"\"\"\n",
    "    This classifier is a primitive baseline, which just predicts the most common class each time.\n",
    "    Naive Bayes should definitely beat this.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y): pass\n",
    "    def predict(self, X): return len(X)*['ham']\n",
    "\n",
    "    \n",
    "def train_evaluate(classifier, X, y):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Apply train-test split.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)\n",
    "    # Inititialize and train classifier.\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Evaluate classifier on test data.\n",
    "    yhat_test = classifier.predict(X_test)\n",
    "    cmatrix = confusion_matrix(y_test, yhat_test, labels=['ham', 'spam'])\n",
    "        \n",
    "    return cmatrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cmatrix, classifier_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.matshow(cmatrix, cmap='Greens')\n",
    "    for x in (0, 1):\n",
    "        for y in (0, 1):\n",
    "            ax.text(x, y, cmatrix[y, x])\n",
    "    ax.set_xlabel('predicted label')\n",
    "    ax.set_ylabel('true label')\n",
    "    ax.set_xticklabels(['', 'ham', 'spam'])\n",
    "    ax.set_yticklabels(['', 'ham', 'spam'])\n",
    "    ax.set_title(classifier_name)\n",
    "\n",
    "    \n",
    "ham_classifier = HamClassifier()\n",
    "your_classifier = NaiveBayesSpamClassifier()\n",
    "ham_cmatrix = train_evaluate(ham_classifier, X, y)\n",
    "your_cmatrix = train_evaluate(your_classifier, X, y)\n",
    "\n",
    "plot_confusion_matrix(ham_cmatrix, 'HamClassifier')\n",
    "plot_confusion_matrix(your_cmatrix, 'NaiveBayesSpamClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
